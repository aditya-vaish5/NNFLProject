{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU_without_glove",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vaish5/NNFLProject/blob/master/GRU_without_glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uer1xgJvH6L6",
        "colab_type": "code",
        "outputId": "10eea323-e84d-442b-9ff8-088e87aca750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-27 04:29:50--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13603614 (13M) [text/plain]\n",
            "Saving to: ‘train.en’\n",
            "\n",
            "train.en            100%[===================>]  12.97M  2.94MB/s    in 4.4s    \n",
            "\n",
            "2020-05-27 04:29:55 (2.94 MB/s) - ‘train.en’ saved [13603614/13603614]\n",
            "\n",
            "--2020-05-27 04:29:58--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18074646 (17M) [text/plain]\n",
            "Saving to: ‘train.vi’\n",
            "\n",
            "train.vi            100%[===================>]  17.24M  1.82MB/s    in 11s     \n",
            "\n",
            "2020-05-27 04:30:10 (1.51 MB/s) - ‘train.vi’ saved [18074646/18074646]\n",
            "\n",
            "--2020-05-27 04:30:12--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132264 (129K) [text/plain]\n",
            "Saving to: ‘tst2013.en’\n",
            "\n",
            "tst2013.en          100%[===================>] 129.16K   189KB/s    in 0.7s    \n",
            "\n",
            "2020-05-27 04:30:13 (189 KB/s) - ‘tst2013.en’ saved [132264/132264]\n",
            "\n",
            "--2020-05-27 04:30:16--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 183855 (180K) [text/plain]\n",
            "Saving to: ‘tst2013.vi’\n",
            "\n",
            "tst2013.vi          100%[===================>] 179.55K   186KB/s    in 1.0s    \n",
            "\n",
            "2020-05-27 04:30:17 (186 KB/s) - ‘tst2013.vi’ saved [183855/183855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advDQCZZIi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLEfKM5Q6hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_to_read = 140000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaQsvAUO9Jm",
        "colab_type": "code",
        "outputId": "288cd94b-fca2-42af-d947-8c6410ea285e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "source_sent = []\n",
        "target_sent = []\n",
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('train.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        source_sent.append(line)\n",
        "        if len(source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('train.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        \n",
        "        target_sent.append(line)\n",
        "        if len(target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(source_sent))\n",
        "for i in range(0,sentences_to_read,10000):\n",
        "    print('(',i,') EN: ', source_sent[i])\n",
        "    print('(',i,') VI: ', target_sent[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (133267)\n",
            "( 0 ) EN:  In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .\n",
            "\n",
            "( 0 ) VI:  Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .\n",
            "\n",
            "( 10000 ) EN:  This is an area in the prefrontal cortex , a region where we can use cognition to try to overcome aversive emotional states .\n",
            "\n",
            "( 10000 ) VI:  Đây là một khu vực trong vỏ não trước trán , vùng mà chúng sử dụng tri thức cho việc thử vượt qua trạng thái cảm xúc ác cảm .\n",
            "\n",
            "( 20000 ) EN:  And there are flowers that are self-infertile . That means they can &apos;t -- the pollen in their bloom can &apos;t fertilize themselves .\n",
            "\n",
            "( 20000 ) VI:  có những loài hoa không thể tự thụ phấn . Nghĩa là chúng không thể -- phấn hoa của nó không thể tụ thụ phấn được\n",
            "\n",
            "( 30000 ) EN:  And a lot of this comes together in a philosophy of change that I find really is powerful .\n",
            "\n",
            "( 30000 ) VI:  Và nhiều như vậy hợp lại thành một triết lý của sự thay đổi mà tôi thấy là thực sự rất mạnh .\n",
            "\n",
            "( 40000 ) EN:  Dean Ornish : At first for a long time , I wrote messages in notebooks .\n",
            "\n",
            "( 40000 ) VI:  Dean Ornish : &quot; Trong một khoảng thời gian dài ban đầu , tôi đã viết các tin nhắn trên các cuốn ghi chú .\n",
            "\n",
            "( 50000 ) EN:  World &apos;s first bamboo bike with folding handlebars .\n",
            "\n",
            "( 50000 ) VI:  Chiếc xe đạp bằng tre đầu tiên trên thế giới với ghi đông gập .\n",
            "\n",
            "( 60000 ) EN:  We need to invest more resources into research and treatment of mental illness .\n",
            "\n",
            "( 60000 ) VI:  Chúng ta cần đầu tư nhiều nguồn lực hơn cho công cuộc nghiên cứu và chữa trị về bệnh thần kinh .\n",
            "\n",
            "( 70000 ) EN:  If we are providing knowledge and experience , we need to structure that .\n",
            "\n",
            "( 70000 ) VI:  Nếu chúng ta cung cấp kiến thức và kinh nghiệm , chúng ta cần cơ cấu nó .\n",
            "\n",
            "( 80000 ) EN:  But I say it has to be under the conditions I &apos;ve always worked : no credit , no logos , no sponsoring .\n",
            "\n",
            "( 80000 ) VI:  Nhưng tôi nói nó phải theo các điều kiện tôi luôn luôn làm không có tín dụng , không có biểu tượng , không có tài trợ .\n",
            "\n",
            "( 90000 ) EN:  What would it look like ?\n",
            "\n",
            "( 90000 ) VI:  Nó sẽ trông như thế nào ?\n",
            "\n",
            "( 100000 ) EN:  And the 70 year-old ones , actually they &apos;re better at scouting out the good nesting places , and they also have more progeny every year .\n",
            "\n",
            "( 100000 ) VI:  Và những con 70 tuổi , thực sự giỏi hơn trong việc tìm kiếm một nơi để dựng tổ , và chúng cũng có nhiều con hơn hàng năm\n",
            "\n",
            "( 110000 ) EN:  The next time you dine on sushi -- or sashimi , or swordfish steak , or shrimp cocktail , whatever wildlife you happen to enjoy from the ocean -- think of the real cost .\n",
            "\n",
            "( 110000 ) VI:  Khi bạn thưởng thức sushi , hay sashimi , hay thịt cá kiếm nướng , hay cốc-tai tôm , bất kể thứ gì hoang dã từ đại dương mà bạn thưởng thức , hãy nghĩ về cái giá thực sự phải trả .\n",
            "\n",
            "( 120000 ) EN:  When I laid out my plan , I realized that I faced three main challenges : first , creating a sensor ; second , designing a circuit ; and third , coding a smartphone app .\n",
            "\n",
            "( 120000 ) VI:  Khi lập kế hoạch , tôi nhận ra mình đối mặt với 3 thách thức : thứ nhất , tạo ra một cảm biến ; thứ hai , thiết kế bảng mạch ; thứ ba , lập trình ứng dụng .\n",
            "\n",
            "( 130000 ) EN:  Why would you do something that dangerous ?\n",
            "\n",
            "( 130000 ) VI:  Tại sao bạn lại sẵn sàng làm một việc nguy hiểm như thế ?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZo84ESWkhKu",
        "colab_type": "code",
        "outputId": "ccb38b3f-3885-4850-d5db-3fa8369bab36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('tst2013.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        \n",
        "        test_source_sent.append(line)\n",
        "        if len(test_source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('tst2013.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        \n",
        "        \n",
        "        test_target_sent.append(line)\n",
        "        if len(test_target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(test_source_sent))\n",
        "for i in range(0,200,100):\n",
        "    print('(',i,') EN: ', test_source_sent[i])\n",
        "    print('(',i,') VI: ', test_target_sent[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (1268)\n",
            "( 0 ) EN:  When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;\n",
            "\n",
            "( 0 ) VI:  Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\n",
            "\n",
            "( 100 ) EN:  Samuel is 16 . He &apos;s tall . He &apos;s very handsome .\n",
            "\n",
            "( 100 ) VI:  Samuel 16 tuổi . Em cao ráo . Em cũng rất đẹp trai .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlKPSSfRsEk",
        "colab_type": "code",
        "outputId": "68342279-9ae9-4bbe-9cf1-d02eb1b1cb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "len()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-adf3103c7c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: len() takes exactly one argument (0 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaUn80e2BZXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZDxdLL5klY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH_VuWD5lvI",
        "colab_type": "code",
        "outputId": "faa7c212-9284-48a4-d790-a641d03a67b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDp726q5pWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSPT4iAR7Fmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lang_test:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tAZFIx5sAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMVraBNFfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 600\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH \n",
        "        # and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-e3-7E6EoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang = Lang(lang1)\n",
        "    input_test_lang=Lang(lang1)\n",
        "    output_test_lang=Lang(lang2)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [];\n",
        "    test_pairs=[];\n",
        "    for i in range(0,len(target_sent)):\n",
        "      pairs.append([normalizeString(source_sent[i]) ,normalizeString(target_sent[i])])\n",
        "    for j in range(0,len(test_target_sent)):\n",
        "      test_pairs.append([normalizeString(test_source_sent[j]) ,normalizeString(test_target_sent[j])])\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    test_pairs = filterPairs(test_pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(test_pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    for pair in test_pairs:\n",
        "        input_test_lang.addSentence(pair[0])\n",
        "        output_test_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    print(input_test_lang.name, input_test_lang.n_words)\n",
        "    print(output_test_lang.name, output_test_lang.n_words)\n",
        "    return input_lang, output_lang, pairs,input_test_lang, output_test_lang,test_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrcRhETL6mDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJpzUK52MeJ",
        "colab_type": "code",
        "outputId": "21ae2beb-a879-4001-c90a-e4db667b09b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "input_lang, output_lang, pairs,input_test_lang, output__test_lang, test_pairs = prepareData('eng', 'vi')\n",
        "print(random.choice(pairs))\n",
        "print(random.choice(test_pairs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 133267 sentence pairs\n",
            "Trimmed to 133264 sentence pairs\n",
            "Trimmed to 1268 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 41253\n",
            "vi 14314\n",
            "eng 3570\n",
            "vi 1107\n",
            "['why we found people were interested in this is that at work they don apos t feel very expressed .', 'tai sao chung toi thay rang nhung nguoi quan tam en van e nay boi vi trong cong viec ho cam thay khong the hien uoc nhieu .']\n",
            "['i was raised in a country that has been destroyed by decades of war .', 'toi a uoc lon len o mot quoc gia a bi tieu huy boi bao thap nien chien tranh .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICTDvR3Xq-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyNJXJZ5X0kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCRY3wl3YA1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x61wko7eYHtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVvbet88DNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Gamqd8JiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSWSxdv8NF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # print(\"train Iter optimizers set\")\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    # print(\"training pairs for this iteration have been assigned\")\n",
        "    # print(\"training pairs size\")\n",
        "    # print(len(training_pairs))\n",
        "    # print(len(training_pairs[0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(training_pairs[0][0])\n",
        "    criterion = nn.NLLLoss()\n",
        "    batch_number=0\n",
        "    \n",
        "    for epoch in range(1):\n",
        "     for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        # print(iter , \" : printing iter-1 th training pair\")\n",
        "        # print(training_pair)\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        batch_number=batch_number+1#changed by manthan\n",
        "        # print(iter , \" : started training with above tensors\")\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion,MAX_LENGTH)\n",
        "        # print(iter,\" : current iter ended\");\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            model_save_name=\"encoder1_orig.pt\"\n",
        "            path=F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "            torch.save(encoder1.state_dict(),path)\n",
        "            model_save_name=\"attn_decoder1_orig.pt\"\n",
        "            path=F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "            torch.save(attn_decoder1.state_dict(),path)\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "        \n",
        "        \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7-Nfxpuvbh4",
        "colab_type": "code",
        "outputId": "aa0a30e1-50d2-48c0-be4a-1848b43e2502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDY5Z2G8g5L",
        "colab_type": "code",
        "outputId": "23eeda62-db5e-44c3-bcd6-536eecefde8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\n",
        "hidden_size = 512\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "print(\"Encoder initialization done\")\n",
        "# attn_decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "print(\"Decoder initialization done\")\n",
        "\n",
        "trainIters(encoder1, attn_decoder1,133000, print_every=5000)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder initialization done\n",
            "Decoder initialization done\n",
            "6m 15s (- 160m 10s) (5000 3%) 4.4045\n",
            "12m 29s (- 153m 39s) (10000 7%) 4.2110\n",
            "19m 2s (- 149m 48s) (15000 11%) 4.2923\n",
            "25m 42s (- 145m 14s) (20000 15%) 4.2408\n",
            "32m 22s (- 139m 52s) (25000 18%) 4.1694\n",
            "39m 5s (- 134m 11s) (30000 22%) 4.1672\n",
            "45m 53s (- 128m 30s) (35000 26%) 4.1542\n",
            "52m 41s (- 122m 29s) (40000 30%) 4.1077\n",
            "59m 24s (- 116m 10s) (45000 33%) 4.1414\n",
            "66m 18s (- 110m 4s) (50000 37%) 4.0921\n",
            "73m 11s (- 103m 48s) (55000 41%) 4.0773\n",
            "79m 59s (- 97m 19s) (60000 45%) 4.1274\n",
            "86m 43s (- 90m 43s) (65000 48%) 4.0410\n",
            "93m 26s (- 84m 5s) (70000 52%) 4.0538\n",
            "100m 17s (- 77m 33s) (75000 56%) 4.0419\n",
            "107m 8s (- 70m 59s) (80000 60%) 4.0617\n",
            "114m 0s (- 64m 22s) (85000 63%) 4.0634\n",
            "120m 59s (- 57m 48s) (90000 67%) 4.0413\n",
            "127m 50s (- 51m 8s) (95000 71%) 4.0648\n",
            "134m 39s (- 44m 26s) (100000 75%) 4.0031\n",
            "141m 25s (- 37m 42s) (105000 78%) 4.0051\n",
            "148m 18s (- 31m 0s) (110000 82%) 4.0207\n",
            "155m 11s (- 24m 17s) (115000 86%) 3.9841\n",
            "161m 58s (- 17m 32s) (120000 90%) 4.0098\n",
            "168m 48s (- 10m 48s) (125000 93%) 3.9950\n",
            "175m 41s (- 4m 3s) (130000 97%) 4.0043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3uMEJ1pVwdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(encoder1.state_dict(), 'encoder1.pth')\n",
        "torch.save(attn_decoder1.state_dict(), 'decoder.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oke8Bxh4YA5m",
        "colab_type": "code",
        "outputId": "c3c1db27-a07a-41cd-ac91-d393a5398116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "random.choice(pairs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['now this is not to say afghanistan is a place full of people like mullah mustafa .',\n",
              " 'y toi khong phai la afghanistan la noi co ay nhung nguoi nhu mullah mustafa .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8ns1zoJB-W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCEHLIb8Qnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDDqGan2eLxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1dYNPb8eHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    nput=[]\n",
        "    reference=[]\n",
        "    output=[]\n",
        "    for i in range(n):\n",
        "        \n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        nput.append(pair[0])\n",
        "        reference.append(pair[1])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        output.append(output_sentence)\n",
        "        print('')\n",
        "    return output,reference,nput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca5iI5L0BRw",
        "colab_type": "code",
        "outputId": "bc06c77e-c5c4-47c6-c12d-d3f591197a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(input_lang.n_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXfF12H8rNL",
        "colab_type": "code",
        "outputId": "c4c4c769-480f-4264-d2d0-96116de599d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "output,reference,nput=evaluateRandomly(encoder1, attn_decoder1,5)\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> a mammalian fetus if it loses a limb during the first trimester of pregnancy will re grow that limb .\n",
            "= mot bao thai cua ong vat co vu neu mat chi trong thang au thai nghen se tu moc lai chi o\n",
            "< mot ieu nay biet neu no la mot mot mot mot mot o o o <EOS>\n",
            "\n",
            "> now let me stop here .\n",
            "= bay gio e toi dung lai .\n",
            "< gio ay toi toi <EOS>\n",
            "\n",
            "> if we have any doubts about the effects of this separate rule book this statistic is sobering from to the number of nonprofits that really grew that crossed the million annual revenue barrier is .\n",
            "= neu chung ta con lo ngai ve anh huong cua cuon sach thong tri rieng re nay so lieu thong ke nay co the giup tu nam en nam so luong cac to chuc phi loi nhuan tang ang ke con so vuot nguong doanh thu trieu hang nam la .\n",
            "< neu chung ta ta ve ve ve ve cua cua cua cua cua cua cua cua cua la la la la la la la la la la la la la la la la o o o o o . . . . . . . <EOS>\n",
            "\n",
            "> in our prime minister was assassinated and the country came to a complete standstill so we organized a five kilometer united we run campaign .\n",
            "= nam thu tuong cua chung toi bi am sat va at nuoc hoan toan be tac chung toi a to chuc chien dich oan ket chung ta chay dai km\n",
            "< nam nam nam toi toi toi toi toi toi va va va va va va va va va va va va <EOS>\n",
            "\n",
            "> and that apos s the picture i really want to change if we can .\n",
            "= va o la hinh anh ma toi thuc su muon thay oi neu co the .\n",
            "< va o la su that su la toi toi toi toi ta the the the <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mot ieu nay biet neu no la mot mot mot mot mot o o o <EOS>',\n",
              " 'gio ay toi toi <EOS>',\n",
              " 'neu chung ta ta ve ve ve ve cua cua cua cua cua cua cua cua cua la la la la la la la la la la la la la la la la o o o o o . . . . . . . <EOS>',\n",
              " 'nam nam nam toi toi toi toi toi toi va va va va va va va va va va va va <EOS>',\n",
              " 'va o la su that su la toi toi toi toi ta the the the <EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WOs79j0BY_Y",
        "colab_type": "code",
        "outputId": "c34998ff-43eb-4862-e4e9-e06172929744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(output)# !python -v\n",
        "print(reference)\n",
        "print(nput)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' va va va va va va va va va va va va va va va va va va va <EOS>']\n",
            "['no ngoai tam kiem soat cua em va no that tuyet nhung o khong phai la mot con uong su nghiep .']\n",
            "['it apos s out of your control and it apos s awesome and it apos s not a career path .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icCvahalHOMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWda4e48FLT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKVX8GNBzeR",
        "colab_type": "code",
        "outputId": "b4a5c536-3529-4118-cbf7-4a10b1f28590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"so the sweet spot is between and .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f55310bd080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP6AsgTbBrA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_VdBg6EzfT",
        "colab_type": "code",
        "outputId": "78b64502-9691-4218-90f8-d29ac31843ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention( \"so the sweet spot is between and .\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = so the sweet spot is between and .\n",
            "output = . . . . . . . . . . . . . . . . . . . .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpaNLG_FG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_GdRlFcc8",
        "colab_type": "code",
        "outputId": "cc492739-6496-4e91-aa80-b25f93205a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(attentions.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA24gW3JFz35",
        "colab_type": "code",
        "outputId": "24aea4a9-2700-41d8-8776-ec73b6c7b33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f553191c860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-6wIjIdpVNu",
        "colab_type": "text"
      },
      "source": [
        "1. BiLSTM\n",
        "2. GloVE embedding\n",
        "3. presentation\n",
        "4. BLUE Score and how error is calculated here\n",
        "5. Figure out how attention figures are made.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YOZ1jJGndf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "def calc_bleu(reference,nput,output):\n",
        " scores=[]\n",
        " score=0\n",
        " print(score)\n",
        " for sentence in range(len(reference)):\n",
        "   score = sentence_bleu(reference[sentence],output[sentence])\n",
        "   scores.append(score)\n",
        "  \n",
        " \n",
        " for sentence in range(len(reference)):\n",
        "   print(\"input sentence: \",nput[sentence])\n",
        "   print(\"reference sentence:\",reference[sentence])\n",
        "   print(\"output sentence:\",output[sentence])\n",
        "   print(\"BLEU SCORE:\",scores[sentence])\n",
        "\n",
        " return pd.DataFrame({\"input sentence: \":nput,\"reference sentence:\":reference,\"output sentence:\":output,\"BLEU SCORE:\":scores})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da0ifx-y12JJ",
        "colab_type": "code",
        "outputId": "a851d7f7-a0e2-4400-b36d-f8ae050fccd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "calc_bleu(reference,nput,output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "input sentence:  even though they were caught they were eventually released after heavy international pressure .\n",
            "reference sentence: vi mac du a bi bat nhung cuoi cung hoc cung uoc tha ra nho vao suc ep tu cong ong quoc te .\n",
            "output sentence: va cac cac cac cac cac cac cac cac cac cac cac cac cac . <EOS>\n",
            "BLEU SCORE: 0.5328985992883941\n",
            "input sentence:  the chance for greatness for progress and for change dies the moment we try to be like someone else .\n",
            "reference sentence: co hoi cho su vi ai tien bo va cho su thay oi bi dap tat khi ta co gang tro nen giong nhu mot nguoi khac .\n",
            "output sentence: va cac cac cac cac cac cac cac cac cac cac cac cac cac cac cac cac cac cac cac . <EOS>\n",
            "BLEU SCORE: 0.4910411500935599\n",
            "input sentence:  back then we had no idea how much this trip would change our lives .\n",
            "reference sentence: hoi o chung toi khong he biet chuyen i ay se thay oi cuoc song cua chung toi nhu the nao .\n",
            "output sentence: cac cac toi toi toi toi toi toi toi toi toi toi toi cac cac . <EOS>\n",
            "BLEU SCORE: 0.5685331719237912\n",
            "input sentence:  one day we wake up to the news of the desecration of ancient mosques and sufi tombs .\n",
            "reference sentence: mot ngay chung toi thuc giac voi tin tuc ve su bang bo cac en tho co va lang mo cua nguoi sufi .\n",
            "output sentence: va cac cac cac cac cac cac cac cac cac cac cac cac . . . . . <EOS>\n",
            "BLEU SCORE: 0.5246341022861458\n",
            "input sentence:  you know it apos s remarkable how universal the gesture is of handing your camera to a total stranger .\n",
            "reference sentence: ban biet ay ong tac trao may anh cua minh cho mot nguoi hoan toan xa la pho bien tren toan the gioi mot cach ang chu y .\n",
            "output sentence: cac . . . . . . . . . . . . . . . <EOS>\n",
            "BLEU SCORE: 0.5659119256652702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input sentence:</th>\n",
              "      <th>reference sentence:</th>\n",
              "      <th>output sentence:</th>\n",
              "      <th>BLEU SCORE:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>even though they were caught they were eventua...</td>\n",
              "      <td>vi mac du a bi bat nhung cuoi cung hoc cung uo...</td>\n",
              "      <td>va cac cac cac cac cac cac cac cac cac cac cac...</td>\n",
              "      <td>0.532899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the chance for greatness for progress and for ...</td>\n",
              "      <td>co hoi cho su vi ai tien bo va cho su thay oi ...</td>\n",
              "      <td>va cac cac cac cac cac cac cac cac cac cac cac...</td>\n",
              "      <td>0.491041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back then we had no idea how much this trip wo...</td>\n",
              "      <td>hoi o chung toi khong he biet chuyen i ay se t...</td>\n",
              "      <td>cac cac toi toi toi toi toi toi toi toi toi to...</td>\n",
              "      <td>0.568533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one day we wake up to the news of the desecrat...</td>\n",
              "      <td>mot ngay chung toi thuc giac voi tin tuc ve su...</td>\n",
              "      <td>va cac cac cac cac cac cac cac cac cac cac cac...</td>\n",
              "      <td>0.524634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>you know it apos s remarkable how universal th...</td>\n",
              "      <td>ban biet ay ong tac trao may anh cua minh cho ...</td>\n",
              "      <td>cac . . . . . . . . . . . . . . . &lt;EOS&gt;</td>\n",
              "      <td>0.565912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    input sentence:   ... BLEU SCORE:\n",
              "0  even though they were caught they were eventua...  ...    0.532899\n",
              "1  the chance for greatness for progress and for ...  ...    0.491041\n",
              "2  back then we had no idea how much this trip wo...  ...    0.568533\n",
              "3  one day we wake up to the news of the desecrat...  ...    0.524634\n",
              "4  you know it apos s remarkable how universal th...  ...    0.565912\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bigDfvcp--G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}